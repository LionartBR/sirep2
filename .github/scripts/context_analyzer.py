#!/usr/bin/env python3
"""
Analisador AvanÃ§ado de Contexto do RepositÃ³rio
AnÃ¡lise profunda: dependÃªncias, grafos, similaridade semÃ¢ntica, arquitetura
"""

import ast
import os
import sys
import hashlib
import re
from pathlib import Path
from collections import defaultdict, Counter
from typing import List, Dict, Set, Tuple, Any, Optional
from dataclasses import dataclass, field
from difflib import SequenceMatcher
import argparse
import json


@dataclass
class FunctionInfo:
    name: str
    file: Path
    lineno: int
    params: List[str]
    returns: Optional[str]
    calls: Set[str] = field(default_factory=set)
    is_async: bool = False
    complexity: int = 0
    body_lines: int = 0
    has_docstring: bool = False
    decorators: List[str] = field(default_factory=list)
    body_ast: Any = None


@dataclass
class ClassInfo:
    name: str
    file: Path
    lineno: int
    methods: List[str]
    bases: List[str]
    attributes: Set[str] = field(default_factory=set)


@dataclass
class Issue:
    severity: str  # critical, high, medium, low
    category: str
    message: str
    file: Optional[str] = None
    locations: List[str] = field(default_factory=list)
    suggestion: Optional[str] = None
    priority_score: float = 0.0


class AdvancedContextAnalyzer:
    def __init__(self, root_dir: str = "."):
        self.root_dir = Path(root_dir)
        self.functions: Dict[str, List[FunctionInfo]] = defaultdict(list)
        self.classes: Dict[str, List[ClassInfo]] = defaultdict(list)
        self.imports: Dict[Path, Set[str]] = defaultdict(set)
        self.dependency_graph: Dict[str, Set[str]] = defaultdict(set)
        self.function_calls: Dict[str, Set[str]] = defaultdict(set)
        self.issues: List[Issue] = []
        self.all_names: Set[str] = set()
        self.module_exports: Dict[Path, Set[str]] = defaultdict(set)
        self.constants: Dict[Path, Set[str]] = defaultdict(set)
        
    def analyze(self):
        """Executa anÃ¡lise completa multi-camadas"""
        print("ðŸ” Iniciando anÃ¡lise avanÃ§ada de contexto...")
        
        py_files = [f for f in self.root_dir.rglob("*.py") if not self._should_skip(f)]
        print(f"ðŸ“ Analisando {len(py_files)} arquivos Python")
        
        # Fase 1: Coleta de informaÃ§Ãµes
        print("ðŸ“Š Fase 1/5: Coletando metadados...")
        for file in py_files:
            self._deep_analyze_file(file)
        
        # Fase 2: ConstruÃ§Ã£o de grafos
        print("ðŸ•¸ï¸  Fase 2/5: Construindo grafos de dependÃªncia...")
        self._build_dependency_graph()
        
        # Fase 3: DetecÃ§Ãµes avanÃ§adas
        print("ðŸ”¬ Fase 3/5: AnÃ¡lise profunda de cÃ³digo...")
        self._detect_duplicate_functions()
        self._detect_similar_functions_semantic()
        self._detect_broken_imports()
        self._detect_circular_dependencies()
        self._detect_code_smells()
        self._detect_architectural_issues()
        self._detect_unused_code()
        self._detect_inconsistent_naming()
        
        # Fase 4: AnÃ¡lise de qualidade
        print("âœ¨ Fase 4/5: Calculando mÃ©tricas de qualidade...")
        self._calculate_quality_metrics()
        
        # Fase 5: PriorizaÃ§Ã£o e relatÃ³rio
        print("ðŸ“ Fase 5/5: Gerando relatÃ³rio...")
        self._prioritize_issues()
        
        return self._generate_advanced_report()
    
    def _should_skip(self, file: Path) -> bool:
        """Ignora arquivos irrelevantes"""
        skip_patterns = [
            '__pycache__', '.venv', 'venv', 'env', 'migrations', 
            'node_modules', '.pytest_cache', '.git', 'build', 'dist',
            '.eggs', '*.egg-info', '.tox'
        ]
        path_str = str(file)
        return any(pattern in path_str for pattern in skip_patterns)
    
    def _deep_analyze_file(self, file: Path):
        """AnÃ¡lise profunda de arquivo"""
        try:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
                tree = ast.parse(content, filename=str(file))
            
            # Visitor customizado
            visitor = DeepASTVisitor(file, self)
            visitor.visit(tree)
            
        except SyntaxError as e:
            self.issues.append(Issue(
                severity='critical',
                category='syntax_error',
                message=f'Erro de sintaxe: {e.msg}',
                file=str(file.relative_to(self.root_dir)),
                priority_score=100.0
            ))
        except Exception as e:
            self.issues.append(Issue(
                severity='warning',
                category='parse_error',
                message=f'Erro ao analisar: {str(e)}',
                file=str(file.relative_to(self.root_dir)),
                priority_score=10.0
            ))
    
    def _build_dependency_graph(self):
        """ConstrÃ³i grafo de dependÃªncias entre mÃ³dulos"""
        for file, imports in self.imports.items():
            module_name = self._file_to_module(file)
            for imp in imports:
                # Se Ã© import interno
                if self._is_internal_import(imp):
                    self.dependency_graph[module_name].add(imp)
    
    def _file_to_module(self, file: Path) -> str:
        """Converte path de arquivo para nome de mÃ³dulo"""
        rel = file.relative_to(self.root_dir)
        return str(rel).replace('/', '.').replace('\\', '.').replace('.py', '')
    
    def _is_internal_import(self, imp: str) -> bool:
        """Verifica se import Ã© interno ao projeto"""
        external = [
            'os', 'sys', 'json', 're', 'typing', 'datetime', 'collections',
            'pathlib', 'argparse', 'logging', 'subprocess', 'shutil', 'time',
            'numpy', 'pandas', 'django', 'flask', 'requests', 'pytest',
            'sklearn', 'torch', 'tensorflow', 'fastapi', 'sqlalchemy'
        ]
        return not any(imp.startswith(ext) for ext in external)
    
    def _detect_similar_functions_semantic(self):
        """Detecta funÃ§Ãµes semanticamente similares (nÃ£o sÃ³ duplicatas)"""
        all_funcs = []
        for func_list in self.functions.values():
            all_funcs.extend(func_list)
        
        # Comparar cada par de funÃ§Ãµes
        compared = set()
        for i, func1 in enumerate(all_funcs):
            for func2 in all_funcs[i+1:]:
                pair = tuple(sorted([id(func1), id(func2)]))
                if pair in compared:
                    continue
                compared.add(pair)
                
                # Pular se mesma funÃ§Ã£o
                if func1.file == func2.file and func1.lineno == func2.lineno:
                    continue
                
                similarity = self._calculate_similarity(func1, func2)
                
                if similarity > 0.7:  # 70% similar
                    self.issues.append(Issue(
                        severity='medium' if similarity < 0.9 else 'high',
                        category='similar_logic',
                        message=f'FunÃ§Ãµes muito similares ({int(similarity*100)}%): `{func1.name}` e `{func2.name}`',
                        locations=[
                            f"{func1.file.relative_to(self.root_dir)}:{func1.lineno}",
                            f"{func2.file.relative_to(self.root_dir)}:{func2.lineno}"
                        ],
                        suggestion=f'Considere extrair lÃ³gica comum para uma funÃ§Ã£o auxiliar',
                        priority_score=50.0 * similarity
                    ))
    
    def _calculate_similarity(self, func1: FunctionInfo, func2: FunctionInfo) -> float:
        """Calcula similaridade semÃ¢ntica entre funÃ§Ãµes"""
        if func1.body_ast is None or func2.body_ast is None:
            return 0.0
        
        # Converter AST para string normalizada
        code1 = self._normalize_ast(func1.body_ast)
        code2 = self._normalize_ast(func2.body_ast)
        
        # SequenceMatcher para similaridade
        return SequenceMatcher(None, code1, code2).ratio()
    
    def _normalize_ast(self, node) -> str:
        """Normaliza AST removendo nomes especÃ­ficos"""
        if hasattr(ast, 'unparse'):
            code = ast.unparse(node)
        else:
            return str(ast.dump(node))
        
        # Normalizar: remover strings, nÃºmeros especÃ­ficos
        code = re.sub(r'"[^"]*"', '"STR"', code)
        code = re.sub(r'\b\d+\b', 'NUM', code)
        return code
    
    def _detect_circular_dependencies(self):
        """Detecta dependÃªncias circulares"""
        def find_cycle(node, path, visited):
            if node in path:
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                return cycle
            
            if node in visited:
                return None
            
            visited.add(node)
            path.append(node)
            
            for neighbor in self.dependency_graph.get(node, []):
                result = find_cycle(neighbor, path.copy(), visited)
                if result:
                    return result
            
            return None
        
        visited = set()
        for node in self.dependency_graph:
            if node not in visited:
                cycle = find_cycle(node, [], visited)
                if cycle:
                    self.issues.append(Issue(
                        severity='high',
                        category='circular_dependency',
                        message=f'DependÃªncia circular detectada: {" â†’ ".join(cycle)}',
                        suggestion='Refatore para remover dependÃªncia circular (injeÃ§Ã£o de dependÃªncia, interfaces)',
                        priority_score=70.0
                    ))
                    break
    
    def _detect_code_smells(self):
        """Detecta code smells comuns"""
        for func_list in self.functions.values():
            for func in func_list:
                location = f"{func.file.relative_to(self.root_dir)}:{func.lineno}"
                
                # God function (muito longa)
                if func.body_lines > 50:
                    self.issues.append(Issue(
                        severity='medium',
                        category='code_smell',
                        message=f'FunÃ§Ã£o muito longa: `{func.name}` ({func.body_lines} linhas)',
                        locations=[location],
                        suggestion='Divida em funÃ§Ãµes menores com responsabilidades Ãºnicas',
                        priority_score=30.0
                    ))
                
                # Muitos parÃ¢metros
                if len(func.params) > 5:
                    self.issues.append(Issue(
                        severity='low',
                        category='code_smell',
                        message=f'Muitos parÃ¢metros: `{func.name}` ({len(func.params)} params)',
                        locations=[location],
                        suggestion='Considere usar dataclass ou objeto de configuraÃ§Ã£o',
                        priority_score=15.0
                    ))
                
                # Alta complexidade ciclomÃ¡tica
                if func.complexity > 10:
                    self.issues.append(Issue(
                        severity='medium',
                        category='complexity',
                        message=f'Alta complexidade: `{func.name}` (complexidade {func.complexity})',
                        locations=[location],
                        suggestion='Simplifique a lÃ³gica ou divida em funÃ§Ãµes menores',
                        priority_score=25.0
                    ))
                
                # Sem docstring
                if not func.has_docstring and not func.name.startswith('_'):
                    self.issues.append(Issue(
                        severity='low',
                        category='documentation',
                        message=f'FunÃ§Ã£o pÃºblica sem docstring: `{func.name}`',
                        locations=[location],
                        suggestion='Adicione docstring explicando propÃ³sito, parÃ¢metros e retorno',
                        priority_score=5.0
                    ))
    
    def _detect_architectural_issues(self):
        """Detecta problemas arquiteturais"""
        # Detectar mÃ³dulos muito acoplados
        for module, deps in self.dependency_graph.items():
            if len(deps) > 10:
                self.issues.append(Issue(
                    severity='medium',
                    category='architecture',
                    message=f'MÃ³dulo muito acoplado: `{module}` depende de {len(deps)} outros mÃ³dulos',
                    suggestion='Considere aplicar princÃ­pios SOLID, especialmente Dependency Inversion',
                    priority_score=35.0
                ))
        
        # Detectar classes God (muitos mÃ©todos)
        for class_list in self.classes.values():
            for cls in class_list:
                if len(cls.methods) > 15:
                    self.issues.append(Issue(
                        severity='medium',
                        category='architecture',
                        message=f'Classe God detectada: `{cls.name}` com {len(cls.methods)} mÃ©todos',
                        locations=[f"{cls.file.relative_to(self.root_dir)}:{cls.lineno}"],
                        suggestion='Divida em classes menores com responsabilidades Ãºnicas (Single Responsibility)',
                        priority_score=40.0
                    ))
    
    def _detect_unused_code(self):
        """Detecta cÃ³digo nÃ£o utilizado"""
        # Coletar todas as chamadas de funÃ§Ã£o
        all_calls = set()
        for calls in self.function_calls.values():
            all_calls.update(calls)
        
        # Verificar funÃ§Ãµes nÃ£o privadas que nunca sÃ£o chamadas
        for func_name, func_list in self.functions.items():
            if func_name.startswith('_') or func_name.startswith('test_'):
                continue
            
            if func_name not in all_calls:
                # Verificar se Ã© entry point
                is_entry = any(
                    'main' in func.name or 
                    '__init__' in func.name or
                    any('fastapi' in d or 'flask' in d or 'route' in d for d in func.decorators)
                    for func in func_list
                )
                
                if not is_entry:
                    self.issues.append(Issue(
                        severity='low',
                        category='dead_code',
                        message=f'FunÃ§Ã£o pÃºblica nunca chamada: `{func_name}`',
                        locations=[f"{f.file.relative_to(self.root_dir)}:{f.lineno}" for f in func_list],
                        suggestion='Remova se nÃ£o for necessÃ¡ria ou torne privada (_function)',
                        priority_score=10.0
                    ))
    
    def _detect_inconsistent_naming(self):
        """Detecta inconsistÃªncias de nomenclatura"""
        func_names = list(self.functions.keys())
        
        # PadrÃµes de nomenclatura
        snake_case = [n for n in func_names if '_' in n and n.islower()]
        camelCase = [n for n in func_names if n[0].islower() and any(c.isupper() for c in n)]
        
        if snake_case and camelCase:
            self.issues.append(Issue(
                severity='low',
                category='style',
                message=f'Estilos de nomenclatura misturados: {len(snake_case)} snake_case, {len(camelCase)} camelCase',
                suggestion='Padronize para snake_case (PEP 8)',
                priority_score=8.0
            ))
    
    def _detect_duplicate_functions(self):
        """Detecta funÃ§Ãµes com nomes duplicados"""
        for func_name, func_list in self.functions.items():
            if len(func_list) > 1 and not func_name.startswith('_'):
                self.issues.append(Issue(
                    severity='high',
                    category='duplicate',
                    message=f'FunÃ§Ã£o `{func_name}` duplicada em {len(func_list)} locais',
                    locations=[f"{f.file.relative_to(self.root_dir)}:{f.lineno}" for f in func_list],
                    suggestion='Consolide em um Ãºnico local ou renomeie para refletir diferenÃ§as',
                    priority_score=80.0
                ))
    
    def _detect_broken_imports(self):
        """Detecta imports quebrados"""
        available_modules = set()
        for file in self.root_dir.rglob("*.py"):
            if not self._should_skip(file):
                available_modules.add(self._file_to_module(file))
        
        for file, imports in self.imports.items():
            for imp in imports:
                if not self._is_internal_import(imp):
                    continue
                
                base = imp.split('.')[0]
                if not any(base in mod for mod in available_modules):
                    self.issues.append(Issue(
                        severity='critical',
                        category='broken_import',
                        message=f'Import quebrado: `{imp}` nÃ£o encontrado',
                        file=str(file.relative_to(self.root_dir)),
                        suggestion='Verifique o caminho do mÃ³dulo ou instale dependÃªncia',
                        priority_score=95.0
                    ))
    
    def _calculate_quality_metrics(self):
        """Calcula mÃ©tricas gerais de qualidade"""
        total_functions = sum(len(fl) for fl in self.functions.values())
        avg_complexity = sum(f.complexity for fl in self.functions.values() for f in fl) / max(total_functions, 1)
        
        if avg_complexity > 8:
            self.issues.append(Issue(
                severity='medium',
                category='metrics',
                message=f'Complexidade mÃ©dia alta: {avg_complexity:.1f}',
                suggestion='Considere refatoraÃ§Ã£o geral do projeto',
                priority_score=45.0
            ))
    
    def _prioritize_issues(self):
        """Prioriza issues por impacto"""
        self.issues.sort(key=lambda x: x.priority_score, reverse=True)
    
    def _generate_advanced_report(self) -> str:
        """Gera relatÃ³rio avanÃ§ado"""
        report = ["# ðŸ”¬ RelatÃ³rio AvanÃ§ado de AnÃ¡lise de Contexto\n"]
        
        # Resumo executivo
        critical = [i for i in self.issues if i.severity == 'critical']
        high = [i for i in self.issues if i.severity == 'high']
        medium = [i for i in self.issues if i.severity == 'medium']
        low = [i for i in self.issues if i.severity == 'low']
        
        report.append("## ðŸ“Š Resumo Executivo\n")
        report.append(f"| MÃ©trica | Valor |")
        report.append(f"|---------|-------|")
        report.append(f"| FunÃ§Ãµes totais | {sum(len(fl) for fl in self.functions.values())} |")
        report.append(f"| Classes totais | {sum(len(cl) for cl in self.classes.values())} |")
        report.append(f"| Problemas crÃ­ticos | **{len(critical)}** |")
        report.append(f"| Problemas altos | {len(high)} |")
        report.append(f"| Problemas mÃ©dios | {len(medium)} |")
        report.append(f"| Problemas baixos | {len(low)} |")
        report.append("")
        
        # Score de saÃºde
        health_score = max(0, 100 - (len(critical)*20 + len(high)*10 + len(medium)*5 + len(low)*2))
        emoji = "ðŸŸ¢" if health_score >= 80 else "ðŸŸ¡" if health_score >= 60 else "ðŸ”´"
        report.append(f"### {emoji} Score de SaÃºde: {health_score}/100\n")
        
        # Top 10 problemas prioritÃ¡rios
        if self.issues:
            report.append("## ðŸŽ¯ Top 10 Problemas PrioritÃ¡rios\n")
            for i, issue in enumerate(self.issues[:10], 1):
                severity_emoji = {
                    'critical': 'ðŸš¨',
                    'high': 'âš ï¸',
                    'medium': 'ðŸ’¡',
                    'low': 'â„¹ï¸'
                }
                
                report.append(f"### {i}. {severity_emoji[issue.severity]} {issue.message}\n")
                report.append(f"**Categoria:** {issue.category} | **Prioridade:** {issue.priority_score:.0f}/100\n")
                
                if issue.locations:
                    report.append(f"**Locais:**")
                    for loc in issue.locations[:3]:
                        report.append(f"- `{loc}`")
                elif issue.file:
                    report.append(f"**Arquivo:** `{issue.file}`")
                
                if issue.suggestion:
                    report.append(f"\nðŸ’¡ **SugestÃ£o:** {issue.suggestion}\n")
                
                report.append("")
        
        # Problemas por categoria
        if self.issues:
            categories = defaultdict(list)
            for issue in self.issues:
                categories[issue.category].append(issue)
            
            report.append("## ðŸ“‹ Problemas por Categoria\n")
            for category, issues in sorted(categories.items(), key=lambda x: len(x[1]), reverse=True):
                report.append(f"- **{category}**: {len(issues)} problema(s)")
            report.append("")
        
        # AnÃ¡lise de dependÃªncias
        if self.dependency_graph:
            report.append("## ðŸ•¸ï¸ AnÃ¡lise de DependÃªncias\n")
            top_coupled = sorted(
                [(m, len(deps)) for m, deps in self.dependency_graph.items()],
                key=lambda x: x[1],
                reverse=True
            )[:5]
            
            if top_coupled:
                report.append("**MÃ³dulos mais acoplados:**")
                for module, count in top_coupled:
                    report.append(f"- `{module}`: {count} dependÃªncias")
                report.append("")
        
        if not self.issues:
            report.append("## âœ… Excelente!\n")
            report.append("Nenhum problema detectado. O cÃ³digo estÃ¡ bem estruturado e consistente! ðŸŽ‰")
        
        report.append("\n---")
        report.append("*Gerado por AnÃ¡lise AvanÃ§ada de Contexto | ")
        report.append(f"{len(self.issues)} problemas detectados em {sum(len(fl) for fl in self.functions.values())} funÃ§Ãµes*")
        
        return "\n".join(report)


class DeepASTVisitor(ast.NodeVisitor):
    """Visitor customizado para anÃ¡lise profunda de AST"""
    
    def __init__(self, file: Path, analyzer: AdvancedContextAnalyzer):
        self.file = file
        self.analyzer = analyzer
        self.current_class = None
    
    def visit_FunctionDef(self, node):
        """Visita definiÃ§Ã£o de funÃ§Ã£o"""
        func_info = FunctionInfo(
            name=node.name,
            file=self.file,
            lineno=node.lineno,
            params=[arg.arg for arg in node.args.args],
            returns=ast.unparse(node.returns) if node.returns else None,
            is_async=isinstance(node, ast.AsyncFunctionDef),
            complexity=self._calculate_complexity(node),
            body_lines=len(node.body),
            has_docstring=ast.get_docstring(node) is not None,
            decorators=[ast.unparse(d) for d in node.decorator_list],
            body_ast=node
        )
        
        # Registrar chamadas de funÃ§Ã£o
        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Name):
                    func_info.calls.add(child.func.id)
                    self.analyzer.function_calls[func_info.name].add(child.func.id)
                elif isinstance(child.func, ast.Attribute):
                    func_info.calls.add(child.func.attr)
        
        self.analyzer.functions[node.name].append(func_info)
        self.analyzer.all_names.add(node.name)
        self.generic_visit(node)
    
    def visit_AsyncFunctionDef(self, node):
        """Visita funÃ§Ã£o async"""
        self.visit_FunctionDef(node)
    
    def visit_ClassDef(self, node):
        """Visita definiÃ§Ã£o de classe"""
        class_info = ClassInfo(
            name=node.name,
            file=self.file,
            lineno=node.lineno,
            methods=[n.name for n in node.body if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))],
            bases=[ast.unparse(base) for base in node.bases]
        )
        
        self.analyzer.classes[node.name].append(class_info)
        self.analyzer.all_names.add(node.name)
        self.current_class = node.name
        self.generic_visit(node)
        self.current_class = None
    
    def visit_Import(self, node):
        """Visita import"""
        for alias in node.names:
            self.analyzer.imports[self.file].add(alias.name)
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node):
        """Visita from import"""
        module = node.module or ''
        for alias in node.names:
            full_import = f"{module}.{alias.name}" if module else alias.name
            self.analyzer.imports[self.file].add(full_import)
        self.generic_visit(node)
    
    def _calculate_complexity(self, node) -> int:
        """Calcula complexidade ciclomÃ¡tica"""
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        return complexity


def main():
    parser = argparse.ArgumentParser(description='AnÃ¡lise avanÃ§ada de contexto')
    parser.add_argument('--root', default='.', help='DiretÃ³rio raiz')
    parser.add_argument('--output', default='report.md', help='Arquivo de saÃ­da')
    parser.add_argument('--json', help='Salvar tambÃ©m em JSON')
    args = parser.parse_args()
    
    analyzer = AdvancedContextAnalyzer(args.root)
    report = analyzer.analyze()
    
    # Salvar markdown
    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… RelatÃ³rio salvo em: {args.output}")
    
    # Salvar JSON se solicitado
    if args.json:
        json_data = {
            'issues': [
                {
                    'severity': i.severity,
                    'category': i.category,
                    'message': i.message,
                    'file': i.file,
                    'locations': i.locations,
                    'suggestion': i.suggestion,
                    'priority': i.priority_score
                }
                for i in analyzer.issues
            ],
            'stats': {
                'total_functions': sum(len(fl) for fl in analyzer.functions.values()),
                'total_classes': sum(len(cl) for cl in analyzer.classes.values()),
                'total_issues': len(analyzer.issues)
            }
        }
        
        with open(args.json, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2)
        
        print(f"ðŸ“Š Dados JSON salvos em: {args.json}")
    
    # Exit code
    critical = sum(1 for i in analyzer.issues if i.severity == 'critical')
    if critical > 0:
        print(f"\nðŸš¨ {critical} problema(s) crÃ­tico(s) detectado(s)")
        sys.exit(1)


if __name__ == '__main__':
    main()